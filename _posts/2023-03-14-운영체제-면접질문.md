---
layout: post
title: "운영체제 면접 질문 모음"
author: "Poogle"
categories: [BackEnd]
sitemap:
changefreq: daily
priority: 1.0
comments: true
tag: []

---

> 참고 링크
> 
> [Backend-Interview-Question](https://github.com/ksundong/backend-interview-question)
> 
> [[기술 면접 준비 - 1일차] 운영체제](https://imbf.github.io/interview/2020/11/26/NAVER-Interview-Preparation-1.html)
> 


# 📌 Process & Thread

## ❓ Core란 무엇인가요?
* CPU 기본 계산 단위를 의미합니다.

## ❓ Process란 무엇이며 어떤 메모리 구조로 되어있나요?
* 실행중인 프로그램을 의미하고 보조저장장치로부터 메모리에 적재되어 CPU의 할당을 받을 수 있는 단위를 의미합니다.
* 메모리 구조
  * 실행 코드가 저장되는 `text` 영역
  * 전역 변수 등을 수록하는 `data` 영역
  * 프로세스 실행 중에 동적으로 할당되는 메모리인 `heap` 영역
  * 함수의 매개변수, 복귀 주소와 로컬 변수와 같은 임시 자료를 갖는 `stack` 영역
* text, data, heap, stack 영역을 포함하는 구조의 메모리를 가지고 이들은 프로세스 간 공유가 되지 않습니다.

## ❓ 프로세스는 운영체제에 어떻게 저장되나요?
* PCB(Process Control Block)
  * 특정 프로세스에 대한 중요한 정보를 저장하고 있는 운영체제의 자료구조인 PCB를 통해 저장됩니다.
  * PID, Process Status, PC(프로세스 실행을 위한 다음 명령의 주소를 표시), CPU 레지스터, CPU 스케줄링 정보 등으로 구성되어 있습니다.

## ❓ 프로세스 동기화란 무엇이며 관련된 문제 상황에는 무엇이 있을까요?
* 다중 프로세스 환경에서 자원 등에 한 프로세스만이 접근가능하도록 하는 것을 의미합니다.
* 프로세스 동기화를 하지 않으면 동시에 공유 자원에 접근할 수 있어 데이터의 일관성이 깨질 수 있습니다.
* **Race Condition(경쟁 상태)**
  * 여러 프로세스나 스레드가 동기화 메커니즘 없이 자원에 접근하려는 상황을 의미합니다.
  * 공유된 자원에 대한 접근 순서에 따라 실행 결과가 달라질 수 있는 상황을 의미합니다.
* **Critical Section(임계 구역)**
  * 여러 스레드가 동시에 접근해서는 안되는 공유자원에 접근하는 코드 블럭을 의미합니다.
  * 한 임계구역에 하나의 스레드 혹은 프로세스만 접근이 가능해야 합니다.
  * 임계 구역에 접근하는 것을 제어하기 위해 `세마포어`, `뮤텍스`와 같은 매커니즘을 사용합니다.

## ❓ 임계 구역 문제를 해결하기 위한 조건(모두 충족해야함)은 무엇인가요?
* `상호 배제(Mutual Exclusion)`: 한 프로세스가 임계구역에서 동작중이면 다른 프로세스는 접근할 수 없습니다.
* `진행(Progress)`: 임계구역에서 작업중인 프로세스가 없다면 입계구역으로 진입하려는 프로세스를 적절히 선택해서 진입할 수 있도록 합니다.
* `유한 대기(Bounded Waiting)`: 한 프로세스가 임계영역으로 진입을 요청한 후 다른 프로세스는 진입이 유한한 횟수로 제한되어야 합니다. (기아상태 방지)

## ❓ 임계 구역 문제를 해결하기 위한 기법에는 무엇이 있나요?
* `Lock`: 하드웨어 기반 해결책
  * 임계 구역에 진입하기전에 Lock을 얻고, 임계 구역에서 빠져 나올 때 Lock을 방출함으로써 프로세스간에 동기화를 유지합니다.
* `Semaphores`: 소프트웨어 상에서 임계 구역 문제를 해결하기 위한 동기화 도구입니다.
  * 두 개의 프로세스 사이에서 동기화를 유지할 수 있는 이진 세마포
  * 프로세스 세 개 이상의 프로세스 사이에서 동기화를 유지할 수 있는 카운팅 세마포
* `모니터`: 고급 언어의 설계 구조물
  * 개발자의 코드를 상호배제 하게끔 만든 추상화된 데이터 형태

<br>

## ❓ Thread란 무엇인지 설명해주세요.
* 프로세스의 CPU 이용을 위한 기본 단위, 프로세스 내에서 실행되는 실행 흐름의 단위를 의미합니다.
* 스레드는 프로세스 내에서 Stack만 할당받으며 Code, Data, Heap 영역을 같은 프로세스 내의 스레드 간에 공유 O
* 프로세스의 주소 공간이나 자원등을 공유해 프로세스를 여러 실행 흐름으로 실행시킬 수 있음

### 스택을 스레드마다 독립적으로 할당하는 이유?
* 스택은 함수의 인자, 복귀 주소, 지역 변수 등을 저장하기 위해 사용되는 메모리 공간이므로 스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다는 것
* 이는 독립적인 실행 흐름이 추가되는 것이기 때문에 프로세스를 여러 실행 흐름으로 만들기 위해서는 스레드에 스택을 독립적으로 할당해야 함

### PC Register를 스레드마다 독립적으로 할당하는 이유
* PC 값은 다음에 실행될 명령어의 주소를 나타내므로 프로세스의 개별 실행 흐름인 스레드가 독립적으로 명령어들을 실행하기 위해선 스레드에 PC 레지스터가 독립적으로 할당되어야 함

### Multi-Thread Programming
* 멀티스레드 프로그래밍은 하나의 프로세스에서 여러 개의 스레드를 만들어 자원의 생성과 관리의 중복을 최소화하는 것
* 장점 
  * 멀티 프로세스에 비해 메모리 자원소모가 줄어듬
  * 힙 영역을 통해서 스레드간 통신이 가능해서 프로세스간 통신보다 간단
  * 스레드의 컨텍스트 스위칭은 프로세스의 컨텍스트 스위칭보다 빠름
* 단점
  * 힙 영역에 있는 자원을 사용할 때는 경쟁 조건이 발생할 수 있으므로 동기화를 해야 함
  * 동기화를 위해서 락을 과도하게 사용하면 성능이 저하될 수 있음
  * 하나의 스레드가 비정상적으로 동작하면 다른 스레드도 종료될 수 있음

### Thread-Safe의 의미와 설계하는 법
* 두 개 이상의 스레드가 race condition에 들어가거나 같은 객체에 동시에 접근해도 연산결과의 정합성이 보장될 수 있게끔 메모리 가시성이 확보된 상태를 의미
* 설계 방법
  * `java.util.concurrent` 패키지 하위의 클래스를 사용
  * 인스턴스 변수를 두지 않음
  * Singleton 패턴을 사용(이 때, 일반적으로 구현하는 Singleton Pattern은 Thread-safe 하지 않음)
  * 동기화(`synchronized`) 블럭에서 연산을 수행

<br>

## Process와 Thread의 차이
* 프로세스는 운영체제로부터 자원을 할당받지만, 스레드는 프로세스로부터 자원을 할당받고 프로세스의 코드/데이터/힙영역을 공유하기 때문에 좀 더 효율적으로 통신
* 컨텍스트 스위칭도 캐시 메모리를 비우지 않아도 되는 스레드쪽이 빠름
* 스레드는 자원 공유로 인해 문제가 발생할 수 있으니 이를 염두에 둔 프로그래밍을 해야 함

## Multi-Process와 Multi-Thread의 차이
* 멀티 스레드와 멀티 프로세스의 차이는 여러 실행흐름을 프로세스를 통해서 만드느냐 아니면 프로세스 내의 스레드를 통해서 만드느냐의 차이
* 동시에 여러 작업을 수행한다는 점에서 목적은 같지만, 서로 장단점이 존재
* 멀티 프로세스 - 장점
  * 여러 프로세스 중 하나의 프로세스에 문제가 발생한다면 해당 프로세스에서만 문제를 해결하면 되기 때문에 멀티 스레드에서 비해서 상대적으로 안정적
* 멀티 프로세스 - 단점
  * 프로세스 간에 공유 되어지는 메모리가 없기 때문에 프로세스 간의 통신을 위해서 통신 기법이 필요
  * Context Switching 이나 자식 프로세스 생성 시 많은 오버헤드가 발생하기 떄문에 여러 프로세스가 존재하는 경우 프로그램의 수행 시간이 전체적으로 시간이 느려질 수 있음
* 멀티 스레드 - 장점
  * 자식 프로세스를 생성하거나 Context Switching(CPU에서 여러 프로세스를 돌아가면서 작업을 처리하는 과정)과 같은 오버헤드가 많이 발생하는 작업이 없어짐으로 시스템의 처리량이 증가
* 멀티 스레드 - 단점
  * 프로세스의 Code, Heap, Data 메모리 영역을 공유하기 때문에 동기화 문제가 발생할 수 있음
  * 하나의 스레드에서 문제가 발생하면 전체 프로세스가 영향을 받을 수 있음

### Multi-Process, Multi-Thread는 언제 사용할까요?
* CPU가 처리해야하는 task의 특성이 크기가 크지 않으면서 개수가 많을 경우나 실시간성이 중요한 웹과 같은 경우 => 멀티 스레드
* CPU가 처리해야하는 task의 특성이 크기가 크면서 개수가 적은 경우나 실시간성이 중요하지 않은 일괄 처리 같은 경우 => 멀티 프로세스

## Context Switching
* 한 Task가 끝날 때까지 기다리는 것이 아니라 여러 작업을 번갈아가며 실행해서 동시에 처리될 수 있도록 하는 방법
* 인터럽트가 발생하면 현재 프로세스의 상태를 PCB에 저장하고 새로운 프로세스의 상태를 레지스터에 저장하는 방식으로 동작
* 이 때, CPU는 아무런 일을 하지 않으므로 잦은 컨텍스트 스위칭은 성능저하를 일으킬 수 있음
* 스레드는 캐시메모리나 PCB에 저장해야하는 내용이 적고, 비워야 하는 내용도 적기때문에 상대적으로 더 빠른 컨텍스트 스위칭이 일어날 수 있음

<br>

## 스케줄러 (Scheduler)
### 프로세스 스케줄러란?
* 멀티 프로세스 기법을 사용하는 시스템은 프로세스의 실행 순서를 스케줄링 해야만 함 -> 프로세스의 실행 순서를 스케줄링하는 도구: 프로세스 스케줄러
* Job Scheduler: 프로그램이 저장되어 있는 디스크에서 메모리로 프로세스 스케줄링을 담당
* CPU Scheduler: CPU와 메모리 사이의 스케줄링을 담당
  * Ready Queue에 있는 프로세스들을 스케줄링하는 스케줄러
  * FCFS(First Come First Serve): 먼저 Ready Queue에 들어온 프로세스를 먼저 처리하는 스케쥴링 기법
  * SJF(Shortest Job First): CPU Burst Time이 짧은 프로세스를 먼저 처리하는 스케줄링 기법
  * SRT(Shortest Remaining Time First): SJF 기법 기반으로 새로운 프로세스가 도착할 때마다 새로운 스케줄링이 이루어져 가장 짧은 프로세스를 먼저 처리하는 기법
  * Priority Scheduling: 프로세스에 우선순위를 부여하여 우선순위가 높은 프로세스를 먼저 처리하는 기법
  * Round Robin: 프로세스에 CPU 할당 시간을 정해 놓아 CPU를 할당하는 방법
* Swapper: 메모리에서 디스크로 프로세스 스케줄링을 담당

---

<br>

# 교착상태(Deadlock), 기아상태(Starvation)
## 교착상태(Deadlock)
* 서로 다른 프로세스가 서로 점유하고 있는 자원의 반납을 대기하고 있는 상태를 의미
* 발생조건
  * 상호 배제: 한 번에 한 프로세스만 해당 자원을 사용할 수 있어야 함
  * 점유 대기: 할당된 자원을 가진 상태에서 다른 자원을 기다림
  * 비선점: 다른 프로세스가 자원의 사용을 끝낼 때 까지 자원을 뺏을 수 없음
  * 순환대기: 각 프로세스가 순환적으로 다음 프로세스가 요구하는 자원을 가지고 있음
* 해결방법
  * 예방: 4가지 조건 중 하나라도 만족되지 않도록 함
  * 회피: 알고리즘을 데드락이 발생하지 않도록 함
  * 회복: 교착상태가 발생할 때, 해결함
  * 무시: 회복과정의 성능저하가 심하다면 그냥 무시함
  
## 기아상태(Starvation)
* 여러 프로세스가 부족한 자원을 점유하기 위해 경쟁할 때, 특정 프로세스가 영원히 자원 할당이 되지 않는 경우
* 우선순위를 변경(우선순위를 수시로 변경하거나, 오래 기다린 프로세스의 우선순위를 높여주거나, Queue를 사용)

---

<br>

# Semaphore, Mutex
## Semaphore(세마포어)
* 여러 개의 프로세스가 접근 가능한 공유자원을 관리하는 방식
* 세마포어는 뮤텍스가 될 수 있음
* 세마포어는 다른 프로세스가 세마포어를 해제할 수 있음

## Mutex(뮤텍스)
* 한 번에 한 개의 프로세스만 접근 가능하도록 관리하는 방식
* 뮤텍스는 세마포어가 될 수 없음
* 뮤텍스는 락을 획득한 프로세스만 락을 반환할 수 있음

---

<br>

# Sync, Async
## 동기(Sync)와 비동기(Async)의 차이(블로킹, 넌블로킹) / 장단점에 대해 설명해보세요.
* 동기/비동기는 두 개 이상의 무엇인가가 시간을 맞춘다/안맞춘다로 구분 
* 동기는 요청과 동시에 결과가 일어나는 경우를 동기라고 표현, 비동기는 요청과 결과가 동시에 일어나지 않는 경우를 비동기라고 표현
* **동기 방식(Sync)**
  * 메서드 리턴과 결과를 전달받는 시간이 일치하는 명령 실행 방식
  * 동기 방식은 한 함수가 끝나는 시간과 바로 다음의 함수가 시작하는 시간이 같음
* **비동기 방식(Async)**
  * 여러 개의 처리가 함께 실행되는 방식
  * 동기 방식에 비해 단위시간 당 많은 작업을 처리할 수 있음
  * 단, CPU나 메모리를 많이 사용하는 작업을 비동기로 처리하게 되면 과부하가 걸릴 수 있고 프로그램의 복잡도도 증가하게 됨
* 블로킹/논블로킹은 동기/비동기와는 다른 관점으로, 내가 직접 제어할 수 없는 대상(IO/멀티스레드)을 상대하는 방법에 대한 분류
* 요청에 대한 응답을 얻기 까지 다른 실행 흐름들이 기다리는 것을 blocking이라고 하고, 다른 실행 흐름이 요청에 대한 응답을 대기하지 않고 자유롭게 CPU나 메모리 등을 이용하는 상황을 non-blocking 이라고 함
* **블로킹 방식(Blocking)**
  * 대상의 작업이 끝날 때 까지 제어권을 대상이 가지고 있는 것을 의미
* **논블로킹 방식(Non-Blocking)**
  * 대상의 작업 완료여부와 상관없이 새로운 작업을 수행
* 동기 논블로킹은 계속해서 polling을 수행하기 때문에 컨텍스트 스위칭이 지속적으로 발생해 지연이 발생

---

<br>

# Memory
## Swapping 이란 무엇인가요?
* 메모리의 관리를 위해 사용되는 기법
* CPU 할당 시간이 끝난 프로세스의 메모리를 보조기억장치(하드디스크)로 내보내고 다른 프로세스를 메모리로 불러 들이는 것을 의미
* swap-in: 주 기억장치(RAM)으로 불러오는 과정
* swap-out: 보조 기억장치로 내보내는 과정
* swap 에는 큰 디스크 전송시간이 필요하기 때문에 현재에는 메모리 공간이 부족할 때 Swapping이 시작됨

## Swapping을 하면서 발생하는 문제점에 대해서 알고 있나요?
* 단편화(Fragmentation) 문제
  * 프로세스들이 메모리에 적재되고 제거되는 일이 반복되다보면 메모리 사이에 사용 하지 못할 만큼의 작은 자유 공간들이 늘어나게 되는데 이를 단편화라고 함
* 외부 단편화
  * 메모리에서 프로세스 사이 사이 남는 공간들을 의미
* 내부 단편화
  * 프로세스가 사용하는 메모리 공간에서 남는 부분을 의미

## 외부 단편화를 해소하기 위한 방법은 무엇이 있을까요?
* 압축
  * 외부 단편화를 해소하기 위해 프로세스가 사용하는 메모리 공간들을 한쪽으로 몰아, 자유 공간을 확보하는 방법
  * 작업효율이 좋지 않아 잘 사용하지 않음
* 페이징 기법
  * 메모리 공간이 연속적이어야 한다는 제약을 없애기
  * 물리 메모리를 Frame 이라는 고정 크기로 분리하고, 논리 메모리는 페이지라 불리는 고정 크기의 블록으로 분리하는 기법
  * 이러한 페이징 기법을 통해 논리 메모리는 물리 메모리에 저장될 때, 연속되어 저장될 필요가 없고 물리 메모리의 남는 프레임에 적절히 배치됨으로 외부 단편화를 해결
  * 하나의 프로세스가 사용하는 공간을 여러 개의 페이지로 나뉘어서 논리 메모리에서 관리하고, 개별 페이지는 순서에 상관없이 물리 메모리에 있는 프레임에 mapping되어 저장하는 방법
  * 하지만 페이지의 크기는 정해져 있기 때문에 내부 단편화는 발생할 수 있음

## Segmentation 세그멘테이션이란 무엇입니까?
* 프로세스를 물리적 크기의 단위가 아닌 논리적 내용의 단위인 세그먼트로 분할하고 메모리를 할당하며 주소를 변환하는 기법
* 세그먼트들의 크기가 서로 다르기 때문에 메모리를 페이징 기법에서처럼 미리 분할해 둘 수 없고, 메모리에 적재될 때 빈 공간을 찾아 할당하는 사용자 관점의 가상 메모리 관리 기법
* 세그먼트의 단위가 다르기 때문에 메모리에 서로 다른 크기를 가진 여러 세그먼트를 저장할 시 외부 단편화가 생기는 문제점이 존재해 잘 사용하지는 않음

<br>

## Virtual Memory 가상 메모리
* 가상 메모리는 프로세스가 실제 메모리의 크기와 상관없이 메모리를 이용할 수 있도록 지원하는 기술
* 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법이며, 프로그램이 물리 메모리보다 커도 된다는 주요 장점이 있음
* 실제 메모리(RAM, main memory, first storage)와 보조 기억 장치(auxiliary storage, secondary storage)의 Swap 영역으로 구성
* OS는 메모리 관리자(Memory Management Unit)를 통해 메모리를 관리
* 프로세스는 사용하는 메모리가 실제 메모리인지, Swap 영역인지 모름
* Java 에서는 Swap 영역을 잡아주지 않은 경우 OOM(Out Of Memory) 이 발생할 수 있음
* Swap 영역은 실제 메모리가 아니기 때문에 지연시간이 많이 발생하며, 가급적이면 Swap 메모리를 사용하지 않도록 설계하는 것이 좋고, 만약 계속해서 사용하는 양이 증가한다면 메모리 누수를 의심해 볼 수 있음

## 왜 가상 메모리가 나오게 되었는가?
* 실행되는 코드의 전부를 물리 메모리에 존재시켜야 했고, 메모리 용량보다 큰 프로그램은 실행시킬 수 없었음
* 또한 멀티 프로세스상에서 여러 프로그램을 동시에 메모리에 올리기에는 용량의 한계와, 페이지 교체등의 성능 이슈가 발생했기 때문

## 가상 메모리를 통해서 우리는 어떤 장점을 얻을 수 있는가?
* 프로그램의 일부분만 메모리에 올릴 수 있게 되었고 이를 통해 물리 메모리 크기에 제약을 받지 않게 되었음 -> 더 많은 프로그램을 동시에 실행
* swap에 필요한 입출력이 줄었기 때문에 프로그램들이 빠르게 실행된다는 장점을 가지고 있음

## 가상 메모리는 어떻게 동작하는가?
* 가상 메모리는 실제의 물리 메모리 개념과 사용자의 논리 메모리 개념을 분리한 것
* 이로써 작은 메모리를 가지고도 얼마든지 큰 가상 주소 공간을 프로그래머에게 제공할 수 있음
* 가상 주소 공간이란 한 프로세스가 메모리에 저장되는 논리적인 모습을 가상메모리에 구현한 공간
* 프로세스가 요구하는 메모리 공간을 가상메모리에서 제공함으로써 현재 직접적으로 필요치 않는 메모리 공간은 실제 물리 메모리에 올리지 않는 것으로 물리 메모리를 절약할 수 있음
* 가상 메모리는 시스템 라이브러리가 여러 프로세스들 사이에 공유될 수 있도록 함
* 프로세스들이 메모리를 공유하는 것을 가능하게 하고, 프로세스들은 공유 메모리를 통해 통신할 수 있음
* 각 프로세스들은 각자 자신의 주소 공간처럼 인식하지만, 실제 물리 메모리는 공유되고 있음

## 요구 페이징 (Demand Paging)이란 무엇인가?
* 프로그램 실행 시작 시에 프로그램 전체를 디스크에서 물리 메모리에 적재하는 대신, 초기에 필요한 것들만 적재하는 전략을
* 가상 메모리 시스템에서 많이 사용
* 요구 페이징을 사용하는 가상 메모리에서는 실행과정에서 필요해질 때 페이지들이 적재됨

## 페이지 교체 알고리즘이란 무엇인가?
* 요구 페이징에서 언급된대로 프로그램 실행시에 모든 항목이 물리 메모리에 올라오지 않기 때문에, 프로세스의 동작에 필요한 페이지를 요청하는 과정에서 page fault가 발생하게 되면, 원하는 페이지를 보조저장장치에서 가져오게 되는 것을 의미

## 페이지 교체 알고리즘의 순서는 어떻게 되는가?
* 디스크에서 필요한 페이지의 위치를 찾는다.
* 빈 페이지 프레임을 찾는다.
페이지 교체 알고리즘을 통해 희생될(victim) 페이지를 고른다.
희생될 페이지를 디스크에 기록하고, 관련 페이지 테이블을 수정한다.
새롭게 비워진 페이지 테이블 내 프레임에 새 페이지를 읽어오고, 프레임 테이블을 수정한다.
사용자 프로세스 재 시작
페이지 교체 알고리즘에는 어떠한 것들이 있는가?
FIFO 페이지 교체 : 먼저 물리 메모리에 들어온 페이지 순서대로 페이지 교체 시점에 먼저 나가게 된다.
최적 페이지 교체 : 앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체하는 알고리즘이다.
LRU (Least Recently Used) 페이지 교체 : 가장 오랫동안 사용되지 않은 페이지를 선택하여 교체한다. (최적 알고리즘 근사 알고리즘)
LFU (Least Frequently Used) 페이지 교체 : 참조 횟수가 가장 적은 페이지를 교체하는 방법이다.
MFU (Most Frequently Used) 페이지 교체 : 참조 횟수가 가장 많은 페이지를 교체하는 방법이다.
---

<br>

# Caching

캐시가 무엇인지, 왜 캐시를 사용하는지를 알고 있어야 합니다. 관련한 좋은 글을 링크해둡니다. https://parksb.github.io/article/29.html

시간 지역성과 공간 지역성으로 나눌 수 있으며, 시간 지역성은 최근에 접근한 데이터에 다시 접근하는 경향을 의미하고, 공간 지역성은 최근 접근한 데이터의 주변 공간에 다시 접근하는 경향을 의미합니다.

캐시(Cache)
캐시 메모리란 무엇인가?
캐시 메모리란 속도가 빠른 장치와 느린 장치간의 속도차에 따른 병목 현상을 줄이기 위한 범용 메모리이다.

캐시 메모리에서 가장 신경써야 하는 문제는 무엇인가?
캐시 메모리의 역할을 수행하기 위해서는 CPU가 어떤 데이터를 원할 것인가를 예측할 수 있어야 한다. 즉, 적중률(hit rate)을 극대화 시켜야 한다.

적중률(hit rate)을 극대화 시키기 위해 어떻게 해야 하는가?
적중률을 극대화 시키기 위해 데이터 지역성(Locality)의 원리를 사용한다. 즉, Locality란 기억 장치 내의 정보를 균일하게 Access 하는 것이 아닌 어느 한 순간에 특정 부분을 집중적으로 참조하는 특성인 것이다.

지역성은 어떻게 나뉘는가?
데이터 지역성은 대표적으로 시간 지역성(Temporal Locality)과 공간 지역성(Spatial Locality)으로 나뉘고 이는 다음과 같다.

## 캐시의 지역성
시간 지역성 : 최근에 참조된 주소의 내용은 곧 다음에 다시 참조되는 특성.
공간 지역성 : 대부분의 실제 프로그램이 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성
---

<br>
